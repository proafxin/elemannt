\documentclass[elemannt.tex]{subfile}

\begin{document}
	\section{Generalization of General Convolution}
	Let $\mathbf{x}=(x_{1},\ldots,x_{k})$ and $\mathbf{a}=(a_{1},\ldots,a_{n})$ be vectors of positive real numbers. $\{\sqrt[\mathbf{a}]{\mathbf{x}}\}$ denotes the largest positive integer $n$ for which $n^{a_{i}}\leq x_{i}$ for some $1\leq i\leq k$. That is,
		\begin{align*}
			\max\{\sqrt[\mathbf{a}]{\mathbf{x}}\}
				& = \max\{\floor{\sqrt[a_{1}]{x_{1}}},\ldots,\floor{\sqrt[a_{k}]{x_{k}}}\}
		\end{align*}
	For a positive integer $n$, let $n^{\mathbf{a}}\leq\mathbf{x}$ denote that $n\leq\max\{\sqrt[\mathbf{a}]{\mathbf{x}}\}$.

	Let $f$ be a real or complex valued function defined in $k$ variables. For a vector of positive real numbers $\mathbf{a}$, let $\mathbf{x}/\mathbf{a}$ denote the vector $(x_{1}/a_{1},\ldots,x_{k}/a_{1})$, $\floor{\mathbf{x}/\mathbf{a}}$ denote the vector $(\floor{x_{1}/a_{1}},\ldots,\floor{x_{k}/a_{k}})$ and
		\begin{align*}
			f(\mathbf{x})
				& = f(x_{1},\ldots,x_{k})\\
			\func{f}{\dfrac{\mathbf{x}}{n^{\mathbf{a}}}}
				& = \func{f}{\dfrac{x_{1}}{n^{a_{1}}},\ldots,\dfrac{x_{k}}{n^{a_{k}}}}\\
			f\parenthesis{\floor{\dfrac{\mathbf{x}}{n^{\mathbf{a}}}}}
				& = f\parenthesis{\floor{\dfrac{x_{1}}{n^{a_{1}}}},\ldots,\floor{\dfrac{x_{k}}{n^{a_{k}}}}}
		\end{align*}

		\begin{definition}[Generalized Convolution]
			Let the generalized convolution of an arithmetic function $\alpha$ and a function $f$ defined for $k$ real numbers and a positive integer $a$ be
				\begin{align}
					(\alpha\bullet f)(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)\func{f}{\dfrac{\mathbf{x}}{n^{\mathbf{a}}}}\label{eqn:genconv}
				\end{align}
		\end{definition}
	We have the next theorem about the associativity of $\bullet$ convolution.
		\begin{theorem}[Associativity of Generalized Convolution]\label{thm:genassociativity}
			Let $\mathbf{x}$ be a vector of $k$ positive real numbers, $\alpha,\beta$ be arithmetic functions, $a$ be a fixed positive integer and $f(x_{1},\ldots,x_{k})$ be a real or complex valued multivariate function. Then
				\begin{align*}
					(\alpha\bullet(\beta\bullet f))(\mathbf{x}, \mathbf{a})
						& = ((\alpha\ast\beta)\bullet f)(\mathbf{x}, \mathbf{a})
				\end{align*}
			where $f\ast g$ is the usual Dirichlet convolution of arithmetic functions $f$ and $g$.
		\end{theorem}

		\begin{proof}
			From the definition,
			\begin{align*}
				(\beta\bullet f)(\mathbf{x},\mathbf{a})
				& = \sum_{m^{\mathbf{a}}\leq\mathbf{x}}\beta(m)\parenthesis{\dfrac{x_{1}}{m^{a_{1}}},\ldots,\dfrac{x_{k}}{m^{a_{k}}}}\\
				(\alpha\bullet(\beta\bullet f))(\mathbf{x}, \mathbf{a})
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)\parenthesis{(\beta\bullet f)\parenthesis{\dfrac{\mathbf{x}}{n^{\mathbf{a}}},\mathbf{a}}}\\
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)\parenthesis{(\beta\bullet f)\parenthesis{\dfrac{x_{1}}{n^{a_{1}}},\ldots,\dfrac{x_{k}}{n^{a_{k}}}}}\\
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)\sum_{m^{a}\leq{\mathbf{x}/n^{\mathbf{a}}}}\beta(m)f\parenthesis{\dfrac{x_{1}}{m^an^a},\ldots,\dfrac{x_{k}}{m^an^a}}
			\end{align*}
			We can collect the $m$ and $n$ together and write
			\begin{align*}
				(\alpha\bullet(\beta\bullet f))(\mathbf{x},\mathbf{a})
				& = \sum_{(mn)^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)\beta(m)f\parenthesis{\dfrac{x_{1}}{m^{a}n^{a}},\ldots,\dfrac{x_{k}}{m^{a_{k}}n^{a_{k}}}}\\
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\parenthesis{\sum_{d\mid n}\alpha(d)\beta\parenthesis{\dfrac{n}{d}}}f\parenthesis{\dfrac{x_{1}}{n^{a_{1}}},\ldots,\dfrac{x_{k}}{n^{a_{k}}}}\\
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}(\alpha\ast\beta)f\parenthesis{\dfrac{\mathbf{x}}{n^{\mathbf{a}}}}\\
				& = (\alpha\ast\beta)\bullet f(\mathbf{x},\mathbf{a})
			\end{align*}
		\end{proof}

		\begin{theorem}[Inversion of Generalized Convolution]\label{thm:geninverse}
			Let $\alpha$ be an arithmetic function and $f$ be a real or complex valued multivariate function. If
				\begin{align*}
					g(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha(n)f(\mathbf{x}, \mathbf{a})
				\end{align*}
			and $\alpha^{-1}$ is the Dirichlet inverse of $\alpha$, then
				\begin{align*}
					f(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}\alpha^{-1}(n)\func{g}{\dfrac{\mathbf{x}}{n^{\mathbf{a}}}}
				\end{align*}
		\end{theorem}

		\begin{proof}
			First, we see that
			\begin{align*}
				(I\bullet f)(\mathbf{x},\mathbf{a})
				& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}I(n)f(\mathbf{x},\mathbf{a})\\
				& = I(1)f(\mathbf{x},\mathbf{a})+\sum_{\substack{n^{\mathbf{a}}\leq{\mathbf{x}}\\n>1}}I(n)f(\mathbf{x},\mathbf{a})\\
				& = f(\mathbf{x},\mathbf{a})
			\end{align*}
			Since $g=\alpha\bullet f$, we will use \nameref{thm:genassociativity} on $\alpha^{-1}$ and $g$. We have
			\begin{align*}
				(\alpha^{-1}\bullet(\alpha\bullet f))(\mathbf{x},\mathbf{a})
				& = ((\alpha^{-1}\ast\alpha)\bullet f)(\mathbf{x},\mathbf{a})
			\end{align*}
			From the definition of Dirichlet inverse, $\alpha^{-1}\ast\alpha=I$. So, we have
			\begin{align*}
				(\alpha^{-1}\bullet g)(\mathbf{x},\mathbf{a})
				& = (\alpha^{-1}\bullet(\alpha\bullet f))(\mathbf{x},\mathbf{a})\\
				& = ((\alpha^{-1}\ast\alpha)\bullet f)(\mathbf{x}, \mathbf{a})\\
				& = (I\bullet f)(\mathbf{x},\mathbf{a})\\
				& = f(\mathbf{x},\mathbf{a})
			\end{align*}
			Thus, we have the theorem.
		\end{proof}
	If we set $\mathbf{a}=(1),k=1$ and $\mathbf{x}=(x)$ for a real number $x$ in \nameref{thm:genassociativity} and \nameref{thm:geninverse}, we have the usual \nameref{thm:genconv} and \nameref{thm:geninverse}.
		\begin{theorem}
			Let $f$ and $g$ be arithmetic functions and $h=f\ast g$. If
				\begin{align*}
					F(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}f(n)\\
					G(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}g(n)\\
					H(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}h(n)
				\end{align*}
			then we have
				\begin{align*}
					H(\mathbf{x}, \mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}f(n)\parenthesis{\dfrac{\mathbf{x}}{n^{\mathbf{a}}},\mathbf{a}}\\
						& =\sum_{n^{\mathbf{a}}\leq\mathbf{x}}g(n)\func{F}{\dfrac{\mathbf{x}}{n^{\mathbf{a}}},\mathbf{a}}
				\end{align*}
		\end{theorem}

		\begin{proof}
			We can write $H$ as follows.
			\begin{align*}
				H(\mathbf{x}, \mathbf{a})
				& = \sum_{n^{\mathbf{a}}\leq(\mathbf{x})}h(n)\\
				& = \sum_{(de)^{\mathbf{a}}\leq\mathbf{x}}f(d)g(e)\\
				& = \sum_{d^{\mathbf{a}}\leq\mathbf{x}}f(d)\sum_{e^{\mathbf{a}}\leq\mathbf{x}/d^{\mathbf{a}}}g(e)\\
				& = \sum_{d^{\mathbf{a}}\leq\mathbf{x}}f(d)G\parenthesis{\dfrac{\mathbf{x}}{d^{\mathbf{a}}},\mathbf{a}}
			\end{align*}
			We can prove the other part similarly by fixing $e$ and letting $d$ run through for $f$ instead of $g$.
		\end{proof}
	As a corollary, we have the following theorem.
		\begin{theorem}
			Let $f$ be an arithmetic function. If
				\begin{align*}
					F(\mathbf{x},\mathbf{a})
						& = \sum_{n^{\mathbf{a}}\leq\mathbf{x}}f(n)
				\end{align*}
			then we have
				\begin{align*}
					\sum_{n\leq\sqrt[\mathbf{a}]{\mathbf{x}}}\sum_{d\mid n}f(d)
						& = \sum_{n\leq\sqrt[\mathbf{a}]{\mathbf{x}}}\floor{\dfrac{\sqrt[\mathbf{a}]{\mathbf{x}}}{n}} f(n)\\
						& =\sum_{n^{\mathbf{a}}\leq\mathbf{x}}F\parenthesis{\dfrac{\sqrt[\mathbf{a}]{\mathbf{x}}}{n}}
				\end{align*}
		\end{theorem}
	We will now see some applications of generalized convolution $\bullet$. Let $s$ be a fixed positive integer and for the rest of the section, $f$ be defined as
		\begin{align*}
			f(\mathbf{x})
			& = \prod_{i=1}^{k}\floor{x_{i}}
		\end{align*}
	Define the function $u$ as
		\begin{align*}
			u(n)
				& = n^s
		\end{align*}
	From \eqref{eqn:jordansummatory},
		\begin{align*}
			\sum_{d\mid n}J(d)
				& = n^{s}
		\end{align*}
	Using \nameref{thm:mobinv}, we also get that
		\begin{align}
			\mu\ast u
				& = J\label{eqn:inversejordan}
		\end{align}
	Let $F(\mathbf{x})$ be the number of vectors of positive integers $(a_{1},\ldots,a_{k})$ such that $1\leq a_i\leq x_i$ and $\gcd(a_{1},\ldots,a_{k})=1$.
	Then we have
		\begin{align*}
			F(\mathbf{x})
				& = (\mu\bullet f)(\mathbf{x},\mathbf{1})
		\end{align*}

	The total number of vectors such that $1\leq a_i\leq x_i$ is $x_{1}\cdots x_{k}$. Consider an arbitrary vector $(a_{1},\ldots,a_{k})$. If $g=\gcd(a_{1},\ldots,a_{k})>1$, then every $a_i$ has to be divisible by $g$. Then the number of such vectors is
		\begin{align*}
			t(g)
				& = \parenthesis{\dfrac{\mathbf{a}}{g}}\\
				& = \floor{\dfrac{a_{1}}{g}}\cdots\floor{\dfrac{a_{k}}{g}}
		\end{align*}
	We can see that the $t(p)$ vectors which has all elements divisible by $p$ also has all vectors which are divisible by a multiple of $p$. So, if $g$ is composite, and has $r$ prime factors, every vector of the $t(g)$ vectors is also divisible by any of those $r$ prime factors. Using a simple principle of inclusion and exclusion, we see that the number of vectors divisible by $g$ has the sign $\mu(g)$. So, the total number of vectors where they have a common factor other than $1$ is
		\begin{align*}
			\sum_{2\leq g\leq\min(\mathbf{x})}\mu(g)\floor{\dfrac{x_{1}}{g}}\cdots\floor{\dfrac{x_{k}}{g}}
		\end{align*}
	Then the number of vectors where $\gcd(a_{1},\ldots,a_{k})=1$ is
		\begin{align*}
			x_{1}\cdots x_{k}+\parenthesis{\sum_{2\leq g\leq\min(\mathbf{x})}\mu(g)\floor{\dfrac{x_{1}}{g}}\cdots\floor{\dfrac{x_{k}}{g}}}
				& = \sum_{n\leq\min(\mathbf{x})}\mu(n)f(\mathbf{x},\mathbf{1})
		\end{align*}
	Thus, we have the result. As a consequence of this result, we can prove the next result using the fact that the number of non-decreasing sequences $(a_{1},\ldots,a_{k})$ such that $1\leq a_i\leq a_{i+1}\leq n$ is $\binom{n+k-1}{k}$.

	Let $B(n,k)$ be the number of vectors of non-decreasing sequences $(a_{1},\ldots,a_{k})$ such that $1\leq a_{1}\leq\ldots\leq a_{k}\leq n$ and $\gcd(a_{1},\ldots,a_{k})=1$. If for a positive integer $m$, $\mathbf{m}=\underbrace{(m,\ldots,m)}_{k\mbox{ times}}$ and
		\begin{align*}
			f(\mathbf{m})
				& = \binom{m+k-1}{k}
		\end{align*}
	then we have
		\begin{align*}
			B(n,k)
				& = (\mu\bullet f)(\mathbf{n},\mathbf{1})
		\end{align*}

	Next, let $S$ be the sum
		\begin{align*}
			S(\mathbf{x})
				& = \sum_{1\leq a_i\leq x_i}g(\mathbf{a})^{s}
		\end{align*}
	where $g(\mathbf{a})=\gcd(a_{1},\ldots,a_{k})$ for the vector of positive integers $\mathbf{a}=(a_{1},\ldots,a_{k})$. Then we have
		\begin{align}
			S(\mathbf{x})
				& = \sum_{n\leq\mathbf{x}}J_{s}(n)\prod_{i=1}^{k}\floor{\dfrac{x_i}{n}}\label{eqn:Sx1}\\
				& = \sum_{n\leq\mathbf{x}}\mu(n)\parenthesis{\sum_{i\leq\mathbf{x}/n}i^{s}\prod_{j=1}^{k}\floor{\dfrac{x_j}{ni}}}\label{eqn:Sx2}
		\end{align}
	\eqref{eqn:Sx1} follows from \nameref{thm:genassociativity} and \eqref{eqn:inversejordan}.
		\begin{align*}
			(J_{s}\bullet f)(\mathbf{x},\mathbf{1})
				& = (\mu\bullet (u\bullet f))(\mathbf{x},\mathbf{1})
		\end{align*}
	So, we will only prove \eqref{eqn:Sx2}. Consider the vector $(a_{1},\ldots,a_{k})$ and $g=\gcd(a_{1},\ldots,a_{k})$. Letting $a_i=gb_i$, we have that $\gcd(b_{1},\ldots,b_{k})=1$. The number of such vectors is $(\mu\bullet f)(\mathbf{x},\mathbf{1})$. Each of these vectors contribute $g^{s}$ to the sum, so for a particular $g$, the contribution of $g$ in the sum is
		\begin{align*}
			g^{s}(\mu\bullet f)(\mathbf{x},\mathbf{1})
		\end{align*}
	Then by the principle of inclusion and exclusion, we have that
		\begin{align*}
			S(\mathbf{x})
				& = \sum_{n\leq\mathbf{x}}n^{s}(\mu\bullet f)(\mathbf{x},\mathbf{1})\\
				& = (u\bullet(\mu\bullet f))(\mathbf{x},\mathbf{1})
		\end{align*}

		\begin{remark}
			We could prove this result without using $\bullet$ convolution as well. For example, in the case $s=1$, if $d\mid g$ and $d<g$, then $g$ has already appeared in the vectors of $d$. Thus, we cannot consider any $d$ that shares a common factor with $g$. $n\leq g$ will contribute a new sum to the vectors only if $\gcd(n,g)=1$. So, the total sum of $g(\mathbf{a})$ with $\gcd(a_{1},\ldots,a_{k})=g$ is $\varphi(g)$. Generalizing this for arbitrary $s$, we can easily see that the contributed sum for $g$ is
				\begin{align*}
					J_{s}(g)\sum_{n\leq\min(\mathbf{x})/g}f(\mathbf{x}/n)
				\end{align*}
		\end{remark}
\end{document}